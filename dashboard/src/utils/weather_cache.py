"""
Sistema de cach√© para predicciones meteorol√≥gicas.

Mantiene datos de predicci√≥n durante 6 horas para reducir llamadas a la API de AEMET
y mejorar el rendimiento del sistema. Implementa persistencia en disco con metadatos
y limpieza autom√°tica de archivos expirados.

Caracter√≠sticas:
- Cach√© persistente en disco
- Validaci√≥n autom√°tica de expiraci√≥n
- Metadatos de control
- Limpieza autom√°tica

Autor: Sistema de Monitoreo Agr√≠cola
Fecha: 2024
"""

# Librer√≠as est√°ndar
import json
import logging
import os
import pickle
from datetime import datetime, timedelta
from typing import Any, Optional, Tuple

logger = logging.getLogger(__name__)

class WeatherCache:
    """
    Gestor de cach√© para predicciones meteorol√≥gicas.
    
    Almacena datos de predicci√≥n durante 6 horas para:
    - Reducir llamadas a la API de AEMET
    - Mejorar tiempos de respuesta
    - Evitar l√≠mites de rate limiting
    - Optimizar el uso de recursos
    """
    
    def __init__(self, cache_dir: str = "cache") -> None:
        """
        Inicializa el gestor de cach√©.
        
        Args:
            cache_dir: Directorio base para almacenar archivos de cach√©
        """
        # Configuraci√≥n del sistema de cach√©
        self.cache_dir = cache_dir
        self.cache_duration = timedelta(hours=6)  # Duraci√≥n de validez
        
        # Crear estructura de directorios
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # Subdirectorio para predicciones meteorol√≥gicas
        self.weather_cache_dir = os.path.join(self.cache_dir, "weather")
        os.makedirs(self.weather_cache_dir, exist_ok=True)
        
        logger.info(
            f"üíæ WeatherCache inicializado en: {self.weather_cache_dir}"
        )
        logger.debug(
            f"Duraci√≥n de validez: {self.cache_duration.total_seconds()/3600:.1f}h"
        )
    
    def _get_cache_path(self, municipio: str, prediction_type: str) -> str:
        """
        Genera la ruta del archivo de cach√©.
        
        Args:
            municipio: Nombre del municipio
            prediction_type: Tipo de predicci√≥n ('diaria' o 'horaria')
            
        Returns:
            Ruta completa del archivo de cach√©
        """
        # Normalizar nombre para uso como archivo
        safe_municipio = (
            municipio.lower()
            .replace(" ", "_")
            .replace("√∫", "u")
            .replace("√°", "a")
        )
        filename = f"{safe_municipio}_{prediction_type}.pkl"
        return os.path.join(self.weather_cache_dir, filename)
    
    def _get_metadata_path(self, municipio: str, prediction_type: str) -> str:
        """
        Genera la ruta del archivo de metadatos.
        
        Args:
            municipio: Nombre del municipio
            prediction_type: Tipo de predicci√≥n ('diaria' o 'horaria')
            
        Returns:
            Ruta completa del archivo de metadatos
        """
        safe_municipio = (
            municipio.lower()
            .replace(" ", "_")
            .replace("√∫", "u")
            .replace("√°", "a")
        )
        filename = f"{safe_municipio}_{prediction_type}_meta.json"
        return os.path.join(self.weather_cache_dir, filename)
    
    def is_cache_valid(self, municipio: str, prediction_type: str) -> bool:
        """
        Verifica si el cach√© es v√°lido (no ha expirado).
        
        Args:
            municipio: Nombre del municipio
            prediction_type: Tipo de predicci√≥n
            
        Returns:
            True si el cach√© es v√°lido, False en caso contrario
        """
        try:
            meta_path = self._get_metadata_path(municipio, prediction_type)
            cache_path = self._get_cache_path(municipio, prediction_type)
            
            # Verificar existencia de archivos
            if not (os.path.exists(meta_path) and os.path.exists(cache_path)):
                logger.debug(
                    f"üö´ Cach√© no existe para {municipio} ({prediction_type})"
                )
                return False
            
            # Cargar metadatos
            with open(meta_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # Verificar expiraci√≥n
            cached_time = datetime.fromisoformat(metadata['timestamp'])
            now = datetime.now()
            is_valid = (now - cached_time) < self.cache_duration
            
            if is_valid:
                time_left = self.cache_duration - (now - cached_time)
                logger.info(
                    f"‚úÖ Cach√© v√°lido para {municipio} ({prediction_type}) - "
                    f"Expira en {time_left}"
                )
            else:
                logger.info(
                    f"‚è∞ Cach√© expirado para {municipio} ({prediction_type})"
                )
            
            return is_valid
            
        except Exception as e:
            logger.warning(
                f"‚ùå Error verificando cach√© para {municipio} "
                f"({prediction_type}): {e}"
            )
            return False
    
    def get_cached_data(
        self, municipio: str, prediction_type: str
    ) -> Optional[Any]:
        """
        Recupera datos del cach√© si son v√°lidos.
        
        Args:
            municipio: Nombre del municipio
            prediction_type: Tipo de predicci√≥n
            
        Returns:
            Datos de predicci√≥n si est√°n en cach√© y son v√°lidos
        """
        try:
            if not self.is_cache_valid(municipio, prediction_type):
                return None
            
            cache_path = self._get_cache_path(municipio, prediction_type)
            
            with open(cache_path, 'rb') as f:
                data = pickle.load(f)
            
            logger.info(
                f"üìÇ Datos recuperados del cach√© para {municipio} "
                f"({prediction_type})"
            )
            return data
            
        except Exception as e:
            logger.error(
                f"‚ùå Error recuperando cach√© para {municipio} "
                f"({prediction_type}): {e}"
            )
            return None
    
    def save_to_cache(
        self, municipio: str, prediction_type: str, data: Any
    ) -> bool:
        """
        Guarda datos en el cach√©.
        
        Args:
            municipio: Nombre del municipio
            prediction_type: Tipo de predicci√≥n
            data: Datos de predicci√≥n a guardar
            
        Returns:
            True si se guard√≥ correctamente
        """
        try:
            cache_path = self._get_cache_path(municipio, prediction_type)
            meta_path = self._get_metadata_path(municipio, prediction_type)
            
            # Guardar datos
            with open(cache_path, 'wb') as f:
                pickle.dump(data, f)
            
            # Guardar metadatos de control
            metadata = {
                'timestamp': datetime.now().isoformat(),
                'municipio': municipio,
                'prediction_type': prediction_type,
                'data_size': (
                    len(data) if isinstance(data, (list, dict)) else 1
                )
            )
            
            with open(meta_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            logger.info(
                f"üíæ Datos guardados en cach√© para {municipio} "
                f"({prediction_type})"
            )
            return True
            
        except Exception as e:
            logger.error(
                f"‚ùå Error guardando en cach√© para {municipio} "
                f"({prediction_type}): {e}"
            )
            return False
    
    def clear_expired_cache(self) -> int:
        """
        Limpia archivos de cach√© expirados del sistema.
        
        Elimina autom√°ticamente todos los archivos de cach√© que han superado
        el tiempo de validez configurado (6 horas por defecto).
        
        Returns:
            int: N√∫mero de archivos eliminados durante la limpieza
        """
        deleted_count = 0
        
        try:
            if not os.path.exists(self.weather_cache_dir):
                return 0
            
            now = datetime.now()
            
            for filename in os.listdir(self.weather_cache_dir):
                if filename.endswith('_meta.json'):
                    meta_path = os.path.join(self.weather_cache_dir, filename)
                    
                    try:
                        with open(meta_path, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                        
                        cached_time = datetime.fromisoformat(metadata['timestamp'])
                        
                        # Si ha expirado, eliminar archivos
                        if (now - cached_time) >= self.cache_duration:
                            # Eliminar archivo de metadatos
                            os.remove(meta_path)
                            
                            # Eliminar archivo de datos correspondiente
                            cache_filename = filename.replace('_meta.json', '.pkl')
                            cache_path = os.path.join(self.weather_cache_dir, cache_filename)
                            
                            if os.path.exists(cache_path):
                                os.remove(cache_path)
                            
                            deleted_count += 1
                            logger.info(f"üóëÔ∏è Eliminado cach√© expirado: {metadata['municipio']} ({metadata['prediction_type']})")
                    
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Error procesando archivo de cach√© {filename}: {e}")
                        continue
            
            if deleted_count > 0:
                logger.info(f"üßπ Limpieza de cach√© completada: {deleted_count} archivos eliminados")
            
            return deleted_count
            
        except Exception as e:
            logger.error(f"‚ùå Error durante limpieza de cach√©: {e}")
            return 0
    
    def get_cache_info(self) -> dict:
        """
        Obtiene informaci√≥n detallada sobre el estado actual del cach√©.
        
        Recopila estad√≠sticas sobre las predicciones almacenadas, incluyendo
        informaci√≥n de validez, antig√ºedad y tama√±o de datos.
        
        Returns:
            dict: Diccionario con informaci√≥n completa del cach√©:
                - cache_dir: Directorio del cach√©
                - cache_duration_hours: Duraci√≥n de validez en horas
                - cached_predictions: Lista de predicciones con metadatos
        """
        info = {
            'cache_dir': self.weather_cache_dir,
            'cache_duration_hours': self.cache_duration.total_seconds() / 3600,
            'cached_predictions': []
        }
        
        try:
            if not os.path.exists(self.weather_cache_dir):
                return info
            
            for filename in os.listdir(self.weather_cache_dir):
                if filename.endswith('_meta.json'):
                    meta_path = os.path.join(self.weather_cache_dir, filename)
                    
                    try:
                        with open(meta_path, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                        
                        cached_time = datetime.fromisoformat(metadata['timestamp'])
                        now = datetime.now()
                        age_hours = (now - cached_time).total_seconds() / 3600
                        is_valid = age_hours < self.cache_duration.total_seconds() / 3600
                        
                        info['cached_predictions'].append({
                            'municipio': metadata['municipio'],
                            'type': metadata['prediction_type'],
                            'cached_at': metadata['timestamp'],
                            'age_hours': round(age_hours, 2),
                            'is_valid': is_valid,
                            'data_size': metadata.get('data_size', 'unknown')
                        })
                    
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Error leyendo metadatos de {filename}: {e}")
                        continue
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo informaci√≥n de cach√©: {e}")
        
        return info


# Instancia global del cach√©
weather_cache = WeatherCache()


def get_cached_or_fetch_prediction(
    municipio: str, 
    prediction_type: str, 
    fetch_function, 
    *args, 
    **kwargs
) -> Tuple[Any, bool]:
    """
    Funci√≥n de conveniencia para obtener predicciones con cach√© autom√°tico.
    
    Implementa el patr√≥n cache-aside: primero intenta obtener datos del cach√©,
    y si no est√°n disponibles o han expirado, llama a la funci√≥n de fetch
    y guarda el resultado en cach√© para futuras consultas.
    
    Args:
        municipio: Nombre del municipio para la predicci√≥n
        prediction_type: Tipo de predicci√≥n ('diaria' o 'horaria')
        fetch_function: Funci√≥n callable que obtiene datos frescos
        *args: Argumentos posicionales para la funci√≥n de fetch
        **kwargs: Argumentos de palabra clave para la funci√≥n de fetch
        
    Returns:
        Tuple[Any, bool]: Tupla con (datos_prediccion, fue_desde_cache)
            - datos_prediccion: Los datos meteorol√≥gicos obtenidos
            - fue_desde_cache: True si los datos vinieron del cach√©, False si fueron obtenidos frescos
    """
    logger.info(f"üîç Buscando predicci√≥n {prediction_type} para {municipio}")
    
    # Limpiar cach√© expirado antes de verificar
    weather_cache.clear_expired_cache()
    
    # Intentar obtener del cach√©
    cached_data = weather_cache.get_cached_data(municipio, prediction_type)
    
    if cached_data is not None:
        logger.info(f"‚úÖ Usando datos en cach√© para {municipio} ({prediction_type})")
        return cached_data, True
    
    # Si no hay cach√© v√°lido, hacer fetch
    logger.info(f"üåê Obteniendo datos frescos para {municipio} ({prediction_type})")
    
    try:
        fresh_data = fetch_function(*args, **kwargs)
        
        # Guardar en cach√© si los datos son v√°lidos
        if fresh_data:
            weather_cache.save_to_cache(municipio, prediction_type, fresh_data)
            logger.info(f"üíæ Datos guardados en cach√© para {municipio} ({prediction_type})")
        
        return fresh_data, False
        
    except Exception as e:
        logger.error(f"‚ùå Error obteniendo datos frescos para {municipio} ({prediction_type}): {e}")
        return None, False
